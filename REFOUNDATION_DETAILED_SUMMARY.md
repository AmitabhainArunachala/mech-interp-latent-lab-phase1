# OPERATION SAMURAI: Complete Refoundation Summary

## Overview

Transformed a chaotic experimental codebase into a clean, professional, modular research library following strict invariants. **1,136 lines** of new, typed, documented code replacing ad-hoc scripts.

---

## ğŸ—ï¸ What Was Built

### 1. New Directory Structure

Created a strict hierarchy following the "Dojo" architecture:

```
arr/
â”œâ”€â”€ src/                    # The Core - only code that matters
â”‚   â”œâ”€â”€ core/              # Foundation: models, hooks, utilities
â”‚   â”œâ”€â”€ metrics/           # R_V calculation and SVD utilities
â”‚   â”œâ”€â”€ steering/          # Activation patching and KV caching
â”‚   â””â”€â”€ pipelines/         # High-level experiment orchestrators
â”‚
â”œâ”€â”€ prompts/               # The Armory - single source of truth
â”‚   â”œâ”€â”€ bank.json         # 370 prompts in JSON format
â”‚   â””â”€â”€ loader.py         # Strict API, no ad-hoc lists
â”‚
â”œâ”€â”€ boneyard/             # The Graveyard - old experiments archived
â”‚
â””â”€â”€ reproduce_results.py  # Entry point: run standard battery
```

**Rationale**: Clear separation of concerns. Core utilities, metrics, interventions, and experiments are distinct. Old code preserved but isolated.

---

## ğŸ“¦ Module Breakdown

### `src/core/` - Foundation (3 files, ~200 lines)

#### `models.py` - Standardized Model Loading
- **Function**: `load_model(model_name, device, torch_dtype)`
- **Default**: `mistralai/Mistral-7B-v0.1` (Base, not Instruct)
- **Features**:
  - Automatic pad_token handling
  - `torch.float16` by default
  - `device_map="auto"` for multi-GPU
  - Model set to eval mode automatically
- **Rationale**: Instruct models are a confounding factor. Base models are the "reference reality."

#### `hooks.py` - Context Manager Hooks
- **Functions**: `capture_v_projection()`, `capture_hidden_states()`
- **Pattern**: All hooks use Python context managers
- **Guarantee**: Hooks are **always** removed, even on exceptions
- **Example**:
  ```python
  with capture_v_projection(model, layer_idx=27) as storage:
      model(**inputs)
  v_tensor = storage["v"]  # Automatically cleaned up
  ```
- **Rationale**: Prevents hook leaks that cause memory issues and incorrect results.

#### `utils.py` - Behavior Scoring
- **Function**: `behavior_score(text)` - counts recursive keywords
- **Keywords**: "self", "aware", "observe", "conscious", etc.
- **Rationale**: Simple behavioral readout for steering experiments.

---

### `src/metrics/` - R_V Calculation (2 files, ~140 lines)

#### `rv.py` - The Core Metric

**`participation_ratio(v_tensor, window_size=16)`**
- Computes PR = (Î£Î»áµ¢Â²)Â² / Î£(Î»áµ¢Â²)Â² from SVD
- **Numerical stability guards**:
  - Checks for degenerate cases (total_variance < 1e-10)
  - Handles NaN/Inf gracefully
  - Returns NaN on exceptions
- **Window handling**: Uses last W tokens (default 16)

**`compute_rv(model, tokenizer, text, early=5, late=27, window=16)`**
- The **R_V metric**: PR_late / PR_early
- **Measurement Invariant**: Always measures on prompt tokens, not generated tokens
- **Standard conditions**:
  - Early: Layer 5 (after initial processing)
  - Late: Layer 27 (num_layers - 5 for 32-layer models)
  - Window: 16 tokens
- **Returns**: Float (NaN if computation fails)

**Key Implementation Details**:
- Uses `torch.linalg.svd(..., full_matrices=False)` as required
- Handles batch dimensions automatically
- Two forward passes (one for early, one for late) - could be optimized but matches original

---

### `src/steering/` - Interventions (3 files, ~250 lines)

#### `activation_patching.py` - Steering Vectors

**`apply_steering_vector(model, layer_idx, vector, alpha=1.0)`**
- Context manager to inject steering vectors into residual stream
- **Injection point**: Pre-hook on layer input
- **Scaling**: `alpha * vector` added to hidden states
- **Automatic cleanup**: Hook removed on exit

**Use case**: Dose-response experiments (Phase 3)

#### `kv_cache.py` - KV Cache Manipulation

**`capture_past_key_values(model, tokenizer, prompt)`**
- Extracts KV cache from forward pass
- Returns `DynamicCache` (HuggingFace format)

**`extract_kv_list(model, tokenizer, prompt)`**
- Extracts KV as list of (K, V) tuples in float32
- Returns `(kv_list, input_ids)`

**`mix_kv_to_dynamic_cache(base_kv, rec_kv, layer_start, layer_end, alpha)`**
- **Î±-mixing**: Linear interpolation of KV caches
- **Layer range**: Patches layers [layer_start, layer_end)
- **Handles**: Different sequence lengths (truncates to minimum)
- **Returns**: `DynamicCache` ready for generation

**`generate_with_kv(model, tokenizer, prompt, past_key_values, ...)`**
- Generation with pre-computed KV cache
- Handles position_ids and attention_mask correctly
- Supports temperature sampling

**Rationale**: KV patching is the core intervention for Phase 4 (mechanism discovery).

---

### `src/pipelines/` - Experiment Orchestrators (2 files, ~150 lines)

#### `phase1_existence.py` - Existence Proof

**`run_phase1_existence_proof(model_name, device, seed, results_dir)`**
- **Layer sweep**: Measures R_V across all layers (0-31)
- **Prompt battery**: Tests multiple categories (recursive vs baseline)
- **Output**: Two CSVs (layer_sweep.csv, prompt_battery.csv)
- **Standard conditions**: Mistral-7B Base, Layer 5 vs 27

**Rationale**: First phase establishes the symptom exists before investigating mechanism.

---

### `prompts/` - Prompt Bank (2 files)

#### `bank.json` - Single Source of Truth
- **370 prompts** exported from `REUSABLE_PROMPT_BANK`
- **Schema**: Each prompt has:
  - `text`: The prompt string
  - `pillar`: "dose_response", "baselines", "control", etc.
  - `type`: "recursive", "instructional", "completion", "creative"
  - `group`: Specific group (e.g., "L3_deeper", "baseline_math")
  - `level`: Recursion level (1-5) for dose-response prompts
  - `expected_rv_range`: [min, max] for validation

#### `loader.py` - Strict API (~300 lines)

**`PromptLoader` class**:
- Loads from JSON (or falls back to REUSABLE_PROMPT_BANK)
- **Methods**:
  - `get_by_pillar(pillar, limit, seed)` - Filter by pillar
  - `get_by_type(prompt_type, limit, seed)` - Filter by type
  - `get_by_group(group, limit, seed)` - Filter by group
  - `get_balanced_pairs(n_pairs, ...)` - Generate recursive/baseline pairs
  - `get_validated_pairs(n_pairs)` - DEC8-validated pairs

**Convenience functions** (matching old API):
- `get_prompts_by_pillar()`, `get_prompts_by_type()`, `get_validated_pairs()`

**Rationale**: No more ad-hoc prompt lists in `.py` files. Everything comes from JSON with proper filtering.

---

### Entry Point: `reproduce_results.py` (~80 lines)

**Purpose**: One command to reproduce all results

```bash
python reproduce_results.py
```

**Features**:
- Clean CLI with argparse
- Runs Phase 1: Existence Proof
- Creates results directory
- Prints summary and next steps

**Rationale**: A stranger can clone and run this to see the "Geometric Contraction" graph.

---

## ğŸ”„ What Was Refactored

### From `DEC11_2025_FULL_PIPELINE/code/common.py`:

**Extracted**:
- `load_model()` â†’ `src/core/models.py`
- `set_seed()` â†’ `src/core/models.py`
- `capture_v_projection()` â†’ `src/core/hooks.py` (now context manager)
- `participation_ratio()` â†’ `src/metrics/rv.py` (with stability guards)
- `compute_rv()` â†’ `src/metrics/rv.py` (standardized)
- `generate_with_kv()` â†’ `src/steering/kv_cache.py`
- `capture_past_key_values()` â†’ `src/steering/kv_cache.py`
- `behavior_score()` â†’ `src/core/utils.py`

**Removed**:
- `get_prompts_by_pillar()` - Now in `prompts/loader.py`
- Hardcoded prompt lists - Now in `prompts/bank.json`

---

## ğŸ—‚ï¸ What Was Archived

**Moved to `boneyard/`**:
- `DEC11_2025_FULL_PIPELINE/` - Original pipeline code (preserved)
- `ARCHIVE_NOV_2025/` - November experiments
- `DEC_8_2025_RUNPOD_GPU_TEST/` - December 8 experiments
- `DEC_9_EMERGENCY_BACKUP/` - December 9 experiments
- `DEC10_LEARNING_DAY/` - December 10 experiments
- `DEC3_2025_BALI_short_SPRINT/` - December 3 experiments
- `DEC7_2025_SIMANDHARCITY_DIVE/` - December 7 experiments
- `DEC9_2025_RLOOP_MASTER_EXEC/` - December 9 experiments
- `DECEMBER_2025_EXPERIMENTS/` - December experiments

**Rationale**: Failed experiments are valuable for reference, but don't belong in the living codebase.

---

## ğŸ“‹ The Three Invariants (Enforced in Code)

### 1. Measurement Invariant
- âœ… Always measure R_V on **prompt tokens** (last W=16), not generated tokens
- âœ… Always use `torch.linalg.svd(..., full_matrices=False)`
- âœ… Handle degenerate singular values (NaN checks, zero variance checks)

**Enforced in**: `src/metrics/rv.py`

### 2. Model Invariant
- âœ… Default to `Mistral-7B-v0.1` (Base, not Instruct)
- âœ… Always use `torch.float16` and `device_map="auto"`
- âœ… Instruct models treated as separate phenotype

**Enforced in**: `src/core/models.py`

### 3. Intervention Invariant
- âœ… Use Python context managers (`with hook(...):`) for all model modifications
- âœ… Never leave a hook attached after function returns
- âœ… KV Cache patching respects `DynamicCache` structure

**Enforced in**: `src/core/hooks.py`, `src/steering/activation_patching.py`

---

## ğŸ“š Documentation Created

### `README.md` - Complete Guide
- Architecture overview
- R_V metric definition (with LaTeX)
- Quick start guide
- Code patterns and examples
- Standard experimental parameters
- Validated results table
- Debugging tips
- Citation format

### `REFOUNDATION_COMPLETE.md` - Migration Guide
- Completed tasks checklist
- Old â†’ New code migration examples
- Verification commands
- Next steps

---

## âœ… Verification

**All imports work**:
```bash
python3 -c "from src.core import load_model; from src.metrics import compute_rv; from prompts.loader import get_prompts_by_pillar; print('âœ“')"
```

**Entry point ready**:
```bash
python reproduce_results.py --help
```

**Structure verified**:
- 13 Python files in `src/` and `prompts/`
- 1 JSON file (`prompts/bank.json`)
- 1 entry point (`reproduce_results.py`)
- All old code archived in `boneyard/`

---

## ğŸ¯ Key Improvements

1. **Modularity**: Each module has a single responsibility
2. **Type Safety**: All functions have type hints
3. **Documentation**: Every function has a docstring
4. **Reproducibility**: Standard conditions enforced
5. **Clean API**: No more ad-hoc imports from scattered files
6. **Hook Safety**: Context managers prevent leaks
7. **Numerical Stability**: SVD guards prevent crashes
8. **Prompt Management**: Single source of truth (JSON)

---

## ğŸ“Š Statistics

- **New code**: 1,136 lines (typed, documented)
- **Files created**: 13 Python files + 1 JSON file + 2 markdown docs
- **Old code archived**: ~10 directories moved to `boneyard/`
- **Prompts consolidated**: 370 prompts in single JSON file
- **Modules**: 4 main modules (core, metrics, steering, pipelines)

---

## ğŸš€ What's Ready

âœ… **Core library**: Model loading, hooks, metrics, steering  
âœ… **Prompt bank**: JSON + loader API  
âœ… **Phase 1 pipeline**: Existence proof experiment  
âœ… **Entry point**: `reproduce_results.py`  
âœ… **Documentation**: README + migration guide  
âœ… **Boneyard**: Old code preserved but isolated  

---

## ğŸ”œ What's Next (Not Done Yet)

- Port Phase 4 (KV mechanism) to use new structure
- Add visualization utilities for R_V results
- Port remaining phases (2, 3, 5, 6) as needed
- Add unit tests
- Create plotting scripts

---

## ğŸ’¡ Philosophy Applied

**"Precision. Minimalism. Truth."**

- **Code is Law**: Modular, typed, reproducible
- **The Boneyard**: Failed experiments preserved but isolated
- **The Standard**: Mistral-7B Base is reference reality
- **The Metric**: R_V is the compass

---

**Status**: âœ… REFOUNDATION COMPLETE

The repository is now a professional research library ready for publication.

