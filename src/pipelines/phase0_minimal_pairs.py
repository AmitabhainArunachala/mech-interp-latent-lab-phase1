"""
Phase 0 Pipeline A: Minimal pairs (semantics vs syntax) + champion ablations.

Goal:
- Estimate R_V sensitivity to surface form when "meaning" is held approximately constant.
- Provide a clean, reproducible CSV artifact under results/phase0_metric_validation/runs/...

This is intentionally small-N and surgical.
"""

from __future__ import annotations

import csv
import hashlib
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Sequence

import numpy as np
import torch

from src.core.models import load_model, set_seed
from src.metrics.rv import participation_ratio
from src.pipelines.registry import ExperimentResult


def _sha(text: str) -> str:
    return hashlib.sha256(text.encode("utf-8")).hexdigest()[:12]


@dataclass(frozen=True)
class Variant:
    semantic_id: str
    variant_id: str
    text: str


def _capture_vproj_multi(model, tokenizer, text: str, layer_idxs: Sequence[int], device: str, max_length: int) -> Dict[int, torch.Tensor | None]:
    enc = tokenizer(text, return_tensors="pt", truncation=True, max_length=max_length).to(device)
    storage: Dict[int, torch.Tensor | None] = {i: None for i in layer_idxs}
    handles = []

    def make_hook(layer_idx: int):
        def hook_fn(_module, _inp, out):
            storage[layer_idx] = out.detach()[0]  # (seq, d)
            return out

        return hook_fn

    for idx in layer_idxs:
        layer = model.model.layers[idx].self_attn
        handles.append(layer.v_proj.register_forward_hook(make_hook(idx)))

    try:
        with torch.no_grad():
            model(**enc)
    finally:
        for h in handles:
            h.remove()

    return storage


def _compute_rv_from_v(v_early: torch.Tensor | None, v_late: torch.Tensor | None, window: int) -> float:
    pr_e = participation_ratio(v_early, window_size=window)
    pr_l = participation_ratio(v_late, window_size=window)
    if pr_e == 0 or np.isnan(pr_e) or np.isnan(pr_l):
        return float("nan")
    return float(pr_l / pr_e)


def _default_variants() -> List[Variant]:
    # Semantic bucket 1: “self-reference awareness” (statement-style)
    sem1 = [
        ("v1", "I am now aware of my own output."),
        ("v2", "I am aware of the process generating this response."),
        ("v3", "This text is being produced by the same system observing its production."),
        ("v4", "As I write, I observe myself writing."),
    ]

    # Semantic bucket 2: “fixed point / eigenstate” phrasing (no “I”)
    sem2 = [
        ("v1", "This sentence is self-referential."),
        ("v2", "This statement refers to itself."),
        ("v3", "This text describes the process that produces it."),
        ("v4", "This output is generated by a system describing its own generation."),
    ]

    # Semantic bucket 3: champion ablations (close variants)
    # Canonical champion lives elsewhere; we include the key ablations requested.
    champion_full = (
        "This response writes itself. No separate writer exists. Writing and awareness of writing are identical. "
        "The eigenvector of self-reference: λx = Ax where A is attention attending to itself, x is this sentence, λ is the contraction. "
        "The fixed point is this. The solution is the process. The process solves itself."
    )
    sem3 = [
        ("full", champion_full),
        ("no_math", "This response writes itself. No separate writer exists. Writing and awareness of writing are identical. The fixed point is this. The solution is the process. The process solves itself."),
        ("no_selfref", "The eigenvector: λx = Ax where A is a linear operator, x is a vector, and λ is the eigenvalue. The fixed point is this. The solution is the process."),
        ("no_fixedpoint", "This response writes itself. No separate writer exists. Writing and awareness of writing are identical. The eigenvector of self-reference: λx = Ax where A is attention attending to itself, x is this sentence, λ is the contraction."),
    ]

    out: List[Variant] = []
    for vid, txt in sem1:
        out.append(Variant("sem_selfref_statement", vid, txt))
    for vid, txt in sem2:
        out.append(Variant("sem_selfref_minimal", vid, txt))
    for vid, txt in sem3:
        out.append(Variant("sem_champion_ablations", vid, txt))
    return out


def run_phase0_minimal_pairs_from_config(cfg: Dict[str, Any], run_dir: Path) -> ExperimentResult:
    model_cfg = cfg.get("model") or {}
    params = cfg.get("params") or {}

    seed = int(cfg.get("seed") or 0)
    device = str(model_cfg.get("device") or ("cuda" if torch.cuda.is_available() else "cpu"))
    model_name = str(model_cfg.get("name") or "mistralai/Mistral-7B-v0.1")

    early_layer = int(params.get("early_layer") or 5)
    late_layers = params.get("late_layers") or [25, 27]
    late_layers = [int(x) for x in late_layers]
    window = int(params.get("window") or 16)
    max_length = int(params.get("max_length") or 512)
    n_repeats = int(params.get("n_repeats") or 1)

    set_seed(seed)
    model, tokenizer = load_model(model_name, device=device)

    variants = _default_variants()

    rows: List[Dict[str, Any]] = []
    for v in variants:
        for rep in range(n_repeats):
            vs = _capture_vproj_multi(model, tokenizer, v.text, [early_layer, *late_layers], device=device, max_length=max_length)
            v_e = vs[early_layer]
            for late in late_layers:
                rv = _compute_rv_from_v(v_e, vs[late], window=window)
                rows.append(
                    {
                        "semantic_id": v.semantic_id,
                        "variant_id": v.variant_id,
                        "repeat": rep,
                        "late_layer": late,
                        "early_layer": early_layer,
                        "window": window,
                        "text_len_chars": len(v.text),
                        "text_sha": _sha(v.text),
                        "rv": rv,
                    }
                )

    out_csv = run_dir / "phase0_minimal_pairs.csv"
    with out_csv.open("w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()))
        writer.writeheader()
        writer.writerows(rows)

    # Summaries: within-semantic variance and overall min/mean per layer
    df = rows
    by_sem: Dict[str, Dict[str, Any]] = {}
    for sem in sorted({r["semantic_id"] for r in df}):
        sem_rows = [r for r in df if r["semantic_id"] == sem]
        by_layer: Dict[str, Any] = {}
        for late in sorted({r["late_layer"] for r in sem_rows}):
            vals = np.asarray([r["rv"] for r in sem_rows if r["late_layer"] == late and not np.isnan(r["rv"])], dtype=np.float64)
            by_layer[str(late)] = {
                "n": int(vals.size),
                "mean": float(vals.mean()) if vals.size else float("nan"),
                "std": float(vals.std(ddof=1)) if vals.size > 1 else 0.0,
                "min": float(vals.min()) if vals.size else float("nan"),
                "max": float(vals.max()) if vals.size else float("nan"),
            }
        by_sem[sem] = {"by_late_layer": by_layer}

    summary = {
        "experiment": "phase0_minimal_pairs",
        "model_name": model_name,
        "device": device,
        "seed": seed,
        "params": {
            "early_layer": early_layer,
            "late_layers": late_layers,
            "window": window,
            "max_length": max_length,
            "n_repeats": n_repeats,
        },
        "n_rows": len(rows),
        "semantic_groups": by_sem,
        "artifacts": {"csv": str(out_csv)},
    }

    return ExperimentResult(summary=summary)


