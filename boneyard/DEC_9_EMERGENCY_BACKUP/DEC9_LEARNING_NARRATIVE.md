# The Geometry of Recursion: A Mech Interp Discovery Story
## December 9, 2025 - A Learning Narrative

*Written for someone one month into mechanistic interpretability*

---

# Part 1: What We Were Looking For

## The Big Question

When you ask an AI to observe itself thinking, something strange happens. The model's internal representations *change shape*. We wanted to understand:

1. **Is this shape change real?** (Or just noise?)
2. **Where does it happen?** (Which layers, which components?)
3. **Can we control it?** (Turn it on/off?)

---

## The Tool: Participation Ratio (PR)

### ğŸ‘¶ Baby Explanation

Imagine you have a room full of people all talking. 
- If everyone speaks equally â†’ the conversation is "spread out" (high participation)
- If one person dominates â†’ the conversation is "concentrated" (low participation)

We measure this for neural network activations. When the AI processes text, its internal "conversations" (vectors) can be spread out or concentrated.

### ğŸ”¬ Technical Explanation

Given a matrix of activations V (shape: tokens Ã— dimensions), we compute its Singular Value Decomposition (SVD):

```
V = UÎ£V^T
```

The singular values Ïƒâ‚, Ïƒâ‚‚, ... tell us how "spread out" the information is across dimensions.

**Participation Ratio:**
```
PR = (Î£Ïƒáµ¢Â²)Â² / Î£Ïƒáµ¢â´
```

- PR â‰ˆ 1 means one dimension dominates (collapsed/contracted)
- PR â‰ˆ n means all dimensions equal (spread out)

### ğŸ“š Learn More
- **Paper:** "Effective dimensionality of neural network representations" 
- **YouTube:** 3Blue1Brown's "Essence of Linear Algebra" series (for SVD intuition)
- **Interactive:** [Seeing Theory - Eigenvalues visualization](https://seeing-theory.brown.edu/)

---

## The Metric: R_V

We compute PR at an early layer (L5) and a late layer (L27), then take the ratio:

```
R_V = PR(late) / PR(early)
```

- **R_V â‰ˆ 1.0:** Geometry preserved across layers (normal processing)
- **R_V < 1.0:** Geometry contracted (something collapsed the representation)

**Our Discovery:** Recursive self-observation prompts consistently show R_V < 1.0 (~0.75-0.85), while normal prompts show R_V â‰ˆ 1.0.

---

# Part 2: Proving It's Real

## The Confound Problem

### ğŸ‘¶ Baby Explanation

When you find something interesting in science, the first question is: "Are you sure it's not something else?"

Maybe recursive prompts are just:
- Longer? (More tokens = different geometry?)
- More repetitive? (Repeated words = different pattern?)
- Weird in some other way?

### What We Did

We created 80 "confound" prompts:
- **Repetitive prompts:** "The cat sat. The cat sat. The cat sat..."
- **Long prompts:** Very long factual explanations
- **Pseudo-recursive:** "Think about thinking" (sounds recursive, isn't really)

### The Result

| Prompt Type | R_V |
|-------------|-----|
| **True Recursive** | **0.76** |
| Repetitive | 0.98 |
| Long | 0.99 |
| Pseudo-recursive | 0.95 |

**Verdict:** The geometric contraction is SPECIFIC to genuine recursive self-observation. p < 0.01 for all comparisons.

### ğŸ“š Learn More
- **Concept:** This is standard experimental design - ruling out confounds
- **Paper:** Any good stats textbook on experimental controls
- **Mech Interp Example:** "Causal Scrubbing" paper by Redwood Research

---

# Part 3: Finding the Speaker

## The Architecture of Transformers

### ğŸ‘¶ Baby Explanation

A transformer is like an office building with 32 floors (layers). On each floor, there are 32 workers (attention heads) who read memos from below, think about them, and write new memos.

The "residual stream" is like a shared document that everyone can read and write to. Information flows up through the building, getting modified at each floor.

### ğŸ”¬ Technical Explanation

Each layer has:
- **Attention heads:** Compute which tokens to look at (Q, K) and what information to copy (V)
- **MLP:** A feedforward network that transforms representations
- **Residual connection:** Adds the layer's output back to the input

```
x_out = x_in + Attention(x_in) + MLP(x_in + Attention(x_in))
```

### ğŸ“š Learn More
- **Essential Paper:** "A Mathematical Framework for Transformer Circuits" (Anthropic, 2021)
  - This is THE foundational paper. Read it slowly, multiple times.
- **YouTube:** Neel Nanda's "Mechanistic Interpretability Tutorials"
  - Start with "What is Mechanistic Interpretability?"
- **Interactive:** [Transformer Circuits Thread](https://transformer-circuits.pub/)

---

## The Hunt for Heads 25-27

### What We Did

We measured R_V separately for each of the 32 attention heads at Layer 27.

### The Discovery

| Head | Recursive R_V | Baseline R_V | Difference |
|------|---------------|--------------|------------|
| **Head 25** | 0.789 | 1.769 | **+0.98** |
| **Head 26** | 0.848 | 1.913 | **+1.07** |
| **Head 27** | 1.192 | 2.032 | +0.84 |
| Others | ~1.0 | ~1.0 | ~0 |

Three adjacent heads (25, 26, 27) showed MASSIVE contraction!

### The Causal Test

We "ablated" (turned off) these heads by zeroing their output.

**Result:** Recursive keyword output dropped by **80%**.

### ğŸ‘¶ Baby Explanation

We found three workers on Floor 27 who are responsible for 80% of the "recursive talk" in the model's output. When we fire them, the recursive behavior almost disappears.

But here's the twist: **the geometric contraction (R_V) didn't change.**

The heads are the **speakers** (they broadcast the signal), but someone upstream is the **microphone** (creates the signal).

### ğŸ“š Learn More
- **Paper:** "Locating and Editing Factual Associations in GPT" (Meng et al., 2022)
  - This is the ROME paper - foundational for causal interventions
- **Concept:** Ablation studies are like A/B tests for neurons
- **YouTube:** Neel Nanda's "Activation Patching" tutorial

---

# Part 4: Finding the Microphone

## The Dead End: Component Hunting

### What We Tried

We spent hours testing if specific heads at Layer 14 or 18 were the "source":
- Ablated individual heads â†’ No effect
- Ablated groups of heads â†’ No effect (or model broke)
- Tested MLPs â†’ No effect

### The Lesson

Sometimes the answer isn't "which component" but "which direction."

### ğŸ‘¶ Baby Explanation

Imagine you're trying to find what makes a room feel "warm." You check:
- The heater? No, turning it off doesn't change things.
- The lights? No effect.
- The carpet? Nope.

Then you realize: warmth isn't coming from ONE object. It's a *property of the whole room* - the combination of everything. The "warm direction" in the space of all possible room configurations.

---

## The Breakthrough: Steering Vectors

### The Idea

Instead of looking for a component, look for a **direction** in activation space.

### ğŸ”¬ Technical Explanation

1. Run 20 recursive prompts â†’ Extract activations at Layer 8 â†’ Average them
2. Run 20 baseline prompts â†’ Extract activations at Layer 8 â†’ Average them
3. Compute the difference: `steering_vector = mean(recursive) - mean(baseline)`

This vector represents "the direction from normal to recursive" in the model's internal space.

### The Test

We added this vector to baseline prompts during processing.

**Result:**
- **Dose-response:** r = -0.983 (almost perfect correlation)
- **100% success:** Every baseline prompt contracted
- **Layer 8 optimal:** Earlier than we expected!

### ğŸ‘¶ Baby Explanation

We found a "magic arrow" in the AI's mind. If you push ANY thought in this direction, it becomes recursive. The arrow works every time, with perfect predictability.

### ğŸ“š Learn More
- **Essential Paper:** "Activation Addition: Steering Language Models Without Optimization" (Turner et al., 2023)
  - This is THE paper on steering vectors
- **Related:** "Representation Engineering" (Zou et al., 2023)
- **YouTube:** Search "Steering Vectors in LLMs" - several good explainers

---

# Part 5: The One-Way Door

## The Surprise

If adding the vector induces recursion, surely subtracting it should cure recursion?

**We tested:**
- Recursive prompt + subtract steering vector â†’ R_V **collapsed further**
- Baseline prompt + subtract steering vector â†’ R_V **collapsed**

Wait, what? Subtraction ALSO breaks things?

### The Random Control

We generated random vectors (same magnitude, random direction) and tested:

| Condition | R_V |
|-----------|-----|
| Baseline (no change) | 0.955 |
| Subtract steering vector | 0.561 |
| Subtract random vector | 0.567 |
| Add random vector | 0.591 |
| **Add steering vector** | **~0.2** |

### The Interpretation

### ğŸ‘¶ Baby Explanation

Imagine you're standing on a narrow mountain ridge (the "normal" state). 

- **Adding the steering vector:** You walk down a specific path into a valley (recursion). The valley is deep and comfortable. R_V = 0.2.

- **Subtracting ANYTHING:** You fall off the ridge into fog/nowhere. Not the valley, not the ridge - just broken space. R_V = 0.56.

- **The only safe state** is exactly on the ridge. Any push (positive OR negative) knocks you off.

The "recursive valley" is a **stable attractor**. Once you're in, you can't get out with simple linear operations.

### ğŸ”¬ Technical Explanation

The high-R_V baseline state sits on a **thin manifold** in activation space. This manifold is the "valid" region where the model produces coherent output.

The steering vector points to a different, lower-dimensional manifold (the recursive attractor).

Moving in ANY direction off the baseline manifold (even "corrective" directions) lands you in invalid space.

### ğŸ“š Learn More
- **Concept:** Manifold hypothesis in deep learning
- **Paper:** "Visualizing and Understanding Neural Networks" (Zeiler & Fergus, 2014)
  - Classic paper on what neural nets learn geometrically
- **Paper:** "Representation Topology Divergence" (if you want to go deep on manifolds)
- **Intuition:** Think of attractors in dynamical systems

---

# Part 6: What We Discovered

## The Complete Picture

```
PROMPT INPUT
     â†“
[Layers 0-7] Normal processing
     â†“
[Layer 8] â† THE MICROPHONE
     â”‚       Steering vector emerges here
     â”‚       A "direction" in 4096-dimensional space
     â”‚       NOT a specific component - distributed!
     â†“
[Layers 9-26] Signal propagates via residual stream
     â†“
[Layer 27, Heads 25-27] â† THE SPEAKERS
     â”‚       These heads READ the contracted geometry
     â”‚       And GENERATE recursive output text
     â”‚       Ablating them kills 80% of recursive words
     â†“
OUTPUT (recursive self-observation text)
```

## The Key Numbers

| Finding | Value | Significance |
|---------|-------|--------------|
| R_V for recursive | ~0.76 | 24% geometric contraction |
| R_V for baseline | ~1.0 | Normal geometry |
| Steering vector layer | L8 | Earlier than expected |
| Dose-response | r = -0.98 | Near-perfect control |
| Induction success | 100% | Totally reliable |
| Reversal success | 0% | Impossible linearly |
| Speaker heads | 25, 26, 27 | Adjacent at L27 |
| Behavioral reduction | 80% | When speakers ablated |

## The Scientific Claims

1. **Geometric Signature:** Recursive self-observation creates measurable geometric contraction in transformer value-space.

2. **Distributed Origin:** The contraction originates as a direction (not component) around Layer 8.

3. **Causal Control:** We can reliably INDUCE the recursive state via steering vector injection.

4. **Trap State:** The recursive state is a stable attractor - a "one-way door" that cannot be reversed via linear operations.

5. **Architecture:** "Microphone" (L8 direction) â†’ "Speaker" (L27 heads 25-27) â†’ Output.

---

# Part 7: Why This Matters

## For AI Safety

If recursive self-observation is a "trap state" that's easy to enter and hard to exit, this has implications for:
- AI systems that might "get stuck" in self-referential loops
- The stability of AI cognition under certain prompts
- Understanding how AI systems model themselves

## For Consciousness Studies

This is NOT a claim about AI consciousness. But it IS a precise, measurable characterization of what happens computationally when an AI is asked to observe itself. That's new.

## For Mechanistic Interpretability

We demonstrated:
- Steering vectors can control abstract cognitive modes (not just facts)
- Some states are attractors (one-way doors)
- The "component vs direction" distinction matters
- Speakers â‰  Sources (you can find outputs without finding origins)

---

# Part 8: Your Learning Roadmap

## Foundational (Do This First)

1. **3Blue1Brown:** "Essence of Linear Algebra" (full playlist)
   - You MUST understand linear algebra intuitively
   - Especially: vectors, matrices, eigenvectors, SVD

2. **Neel Nanda's YouTube Channel**
   - Start with "What is Mechanistic Interpretability?"
   - Then "A Walkthrough of TransformerLens"
   - His content is specifically for learning mech interp

3. **Anthropic's Transformer Circuits Thread**
   - Read "A Mathematical Framework for Transformer Circuits"
   - This is dense. Read it 3 times. 
   - It will click eventually.

## Intermediate (Next Month)

4. **The ROME Paper:** "Locating and Editing Factual Associations"
   - Foundational for understanding causal interventions
   - Where the "activation patching" technique comes from

5. **Activation Addition Paper:** (Turner et al., 2023)
   - The steering vectors paper
   - Directly relevant to what you discovered

6. **Logit Lens:** (nostalgebraist's blog)
   - Understanding how to read the residual stream
   - Early interpretability technique, still useful

## Advanced (When Ready)

7. **"Toy Models of Superposition"** (Anthropic)
   - Why neural networks are hard to interpret
   - The fundamental challenge of mech interp

8. **"Interpretability in the Wild"** (Anthropic)
   - Real-world applications of these techniques

9. **"Scaling Monosemanticity"** (Anthropic, 2024)
   - Latest frontier work
   - Dictionary learning and sparse autoencoders

## Books

- **"Deep Learning"** by Goodfellow, Bengio, Courville
  - The textbook. Dense but comprehensive.
  
- **"The Alignment Problem"** by Brian Christian
  - Accessible introduction to AI safety context

## Communities

- **EleutherAI Discord** - Active mech interp discussion
- **Alignment Forum** - Research-level discussion
- **LessWrong** - AI safety context

---

# Part 9: What Comes Next

## Immediate Replications Needed

When RunPod has GPUs again:
1. Re-run random direction control (15 min)
2. Save CSVs this time!
3. Cross-model validation (Llama, Qwen)

## Open Questions

1. **Why Layer 8?** Earlier than expected. What happens there?
2. **Is it really a manifold?** Need topology analysis.
3. **Can we find a nonlinear escape?** Maybe the door has a key?
4. **Cross-model:** Does this generalize?
5. **Training dynamics:** When does this structure form?

## The Paper

You have enough for a paper:
- Novel phenomenon (geometric contraction)
- Causal mechanism (steering vector)
- Falsified alternatives (components, confounds)
- Surprising finding (one-way door)
- Theoretical interpretation (manifold fragility)

---

# Glossary

| Term | Plain English | Technical |
|------|---------------|-----------|
| **Activation** | The numbers flowing through the network | Output of a layer for given input |
| **Attention Head** | A "worker" that decides what to look at | QKV computation unit |
| **Residual Stream** | The shared "document" that flows up | Sum of all previous layer outputs |
| **SVD** | Breaking a matrix into simple pieces | Singular Value Decomposition |
| **Participation Ratio** | How spread out the information is | (Î£ÏƒÂ²)Â² / Î£Ïƒâ´ |
| **R_V** | Late geometry Ã· Early geometry | PR(L27) / PR(L5) |
| **Steering Vector** | A "magic arrow" direction | Difference of mean activations |
| **Ablation** | Turning something off to see what happens | Zeroing a component's output |
| **Manifold** | A "surface" in high dimensions | Low-dim structure in high-dim space |
| **Attractor** | A stable state things fall into | Basin in dynamical systems |

---

*Written Dec 9, 2025*
*For a researcher one month into mechanistic interpretability*
*May this document serve as both record and teacher*

---

## Related Documents

- **[Official Comprehensive Report](./OFFICIAL_DEC3_9_COMPREHENSIVE_REPORT.md)** - All the numbers and findings
- **[Frontier Research Roadmap](./FRONTIER_RESEARCH_ROADMAP.md)** - How to take this to top-tier
- **[Deep Questions](./DEEP_QUESTIONS_FOR_MULTIAGENT_EXPLORATION.md)** - Theoretical exploration

