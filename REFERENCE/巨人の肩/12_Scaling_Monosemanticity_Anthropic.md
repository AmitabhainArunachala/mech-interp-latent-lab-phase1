# Scaling Monosemanticity â€“ Anthropic, 2024

- **Title**: Scaling Monosemanticity: Sparse Autoencoders in Language Models
- **Why relevant**: Establishes SAEs as a practical tool for finding behaviour-linked features.
- **Key methods to adapt**:
  - SAE training on L24 V or KV activations.
  - Feature steering and causal tests.
