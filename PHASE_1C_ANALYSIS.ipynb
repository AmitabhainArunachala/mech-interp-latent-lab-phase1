{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PHASE 1C: L4 Contraction Analysis on Mistral 7B\n",
        "## N=320 Prompts | 11-Metric Framework | AIKAGRYA Research\n",
        "\n",
        "**Date**: November 2024  \n",
        "**Model**: Mistral-7B-Instruct-v0.2  \n",
        "**GPU**: RunPod Instance  \n",
        "\n",
        "---\n",
        "\n",
        "### Experiment Overview\n",
        "Running comprehensive analysis of 320 prompts across 16 groups to validate the L4 Contraction Phenomenon:\n",
        "- **Dose-Response**: L1-L5 recursive induction levels (100 prompts)\n",
        "- **Baselines**: Creative, factual, impossible, math, personal (100 prompts)  \n",
        "- **Confounds**: Long control, pseudo-recursive, repetitive (60 prompts)\n",
        "- **Generality**: Zen koans, Yogic witness, Madhyamaka (60 prompts)\n",
        "\n",
        "### Key Hypothesis\n",
        "Recursive self-observation prompts will show **R_V < 1.0** (column space contraction) while all other prompt types show **R_V > 1.0** (expansion).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Environment Setup and Imports\n",
        "# TO BE WRITTEN BY GPT-5\n",
        "\n",
        "\"\"\"\n",
        "TODO for GPT-5:\n",
        "1. Import all necessary libraries (torch, transformers, numpy, pandas, scipy, tqdm)\n",
        "2. Set up CUDA device and memory management\n",
        "3. Configure logging and checkpointing\n",
        "\"\"\"\n",
        "\n",
        "print(\"Ready for Phase 1C implementation...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Load Prompt Bank\n",
        "# TO BE WRITTEN BY GPT-5\n",
        "\n",
        "\"\"\"\n",
        "TODO for GPT-5:\n",
        "1. Load the prompt_bank_1c from n300_mistral_test_prompt_bank.py\n",
        "2. Verify all 320 prompts are loaded\n",
        "3. Create lists organized by group and pillar\n",
        "\"\"\"\n",
        "\n",
        "# exec(open('n300_mistral_test_prompt_bank.py').read())\n",
        "# print(f\"Loaded {len(prompt_bank_1c)} prompts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Model Initialization\n",
        "# TO BE WRITTEN BY GPT-5\n",
        "\n",
        "\"\"\"\n",
        "TODO for GPT-5:\n",
        "1. Load Mistral-7B-Instruct-v0.2 with proper GPU configuration\n",
        "2. Set up tokenizer with padding token\n",
        "3. Verify CUDA availability and memory\n",
        "\n",
        "CRITICAL: Use the exact functions from L4transmissionTEST001.1.ipynb\n",
        "\"\"\"\n",
        "\n",
        "# model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "# model = AutoModelForCausalLM.from_pretrained(...)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(...)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Core Metric Functions\n",
        "# TO BE WRITTEN BY GPT-5\n",
        "\n",
        "\"\"\"\n",
        "TODO for GPT-5: Copy ALL metric functions from L4transmissionTEST001.1.ipynb\n",
        "\n",
        "REQUIRED FUNCTIONS:\n",
        "1. epsilon_last_token() - Layer similarity\n",
        "2. attn_entropy_lastrow() - Attention entropy\n",
        "3. compute_column_space_pr() - R_V metric (CRITICAL!)\n",
        "4. compute_effective_rank() - Dimensionality\n",
        "5. compute_confidence() - Peak probability\n",
        "6. compute_margin() - Decisiveness\n",
        "7. compute_norm() - Activation strength\n",
        "8. compute_pr_attn() - Head agreement\n",
        "9. compute_entropy_normalized() - Length-corrected entropy\n",
        "10. compute_margin_trajectory() - Convergence dynamics\n",
        "11. compute_eigenspectrum_shape() - Value matrix structure\n",
        "\n",
        "CRITICAL: The R_V metric (compute_column_space_pr) must be EXACTLY as in the original!\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Value Matrix Hook System\n",
        "# TO BE WRITTEN BY GPT-5\n",
        "\n",
        "\"\"\"\n",
        "TODO for GPT-5: Implement the ValueMatrixHook context manager\n",
        "\n",
        "CRITICAL: This is essential for capturing V matrices for R_V computation!\n",
        "\n",
        "class ValueMatrixHook:\n",
        "    def __init__(self, model):\n",
        "        # Initialize\n",
        "    \n",
        "    def hook_fn(self, module, input, output):\n",
        "        # Capture V matrix from attention\n",
        "    \n",
        "    def __enter__(self):\n",
        "        # Register hooks\n",
        "    \n",
        "    def __exit__(self, *args):\n",
        "        # Clean up hooks\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Master Analysis Function\n",
        "# TO BE WRITTEN BY GPT-5\n",
        "\n",
        "\"\"\"\n",
        "TODO for GPT-5: Implement analyze_prompt() function\n",
        "\n",
        "def analyze_prompt(prompt, model, tokenizer):\n",
        "    # 1. Tokenize prompt\n",
        "    # 2. Run through model with ValueMatrixHook\n",
        "    # 3. Compute all 11 metrics\n",
        "    # 4. Return results dict\n",
        "    \n",
        "    return {\n",
        "        'prompt': prompt[:50] + '...',\n",
        "        'R_V': r_v_value,\n",
        "        'effective_rank': eff_rank,\n",
        "        # ... all other metrics\n",
        "    }\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Main Processing Loop\n",
        "# TO BE WRITTEN BY GPT-5\n",
        "\n",
        "\"\"\"\n",
        "TODO for GPT-5: Process all 320 prompts with progress tracking\n",
        "\n",
        "REQUIREMENTS:\n",
        "1. Process in batches (e.g., 10 prompts) to manage memory\n",
        "2. Show progress bar (tqdm)\n",
        "3. Save checkpoints every 50 prompts\n",
        "4. Clear CUDA cache between batches\n",
        "5. Handle errors gracefully\n",
        "\n",
        "STRUCTURE:\n",
        "results = []\n",
        "for i, (prompt_id, prompt_data) in enumerate(tqdm(prompt_bank_1c.items())):\n",
        "    try:\n",
        "        result = analyze_prompt(prompt_data['text'], model, tokenizer)\n",
        "        result['id'] = prompt_id\n",
        "        result['group'] = prompt_data['group']\n",
        "        result['pillar'] = prompt_data['pillar']\n",
        "        results.append(result)\n",
        "        \n",
        "        # Checkpoint saving\n",
        "        if (i + 1) % 50 == 0:\n",
        "            pd.DataFrame(results).to_csv(f'checkpoint_{i+1}.csv')\n",
        "            \n",
        "        # Memory management\n",
        "        if (i + 1) % 10 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error on prompt {prompt_id}: {e}\")\n",
        "        continue\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Results Analysis and Statistics\n",
        "# TO BE WRITTEN BY GPT-5\n",
        "\n",
        "\"\"\"\n",
        "TODO for GPT-5: Compute group statistics and visualizations\n",
        "\n",
        "1. GROUP STATISTICS:\n",
        "   - Mean R_V per group\n",
        "   - Standard deviation\n",
        "   - Min/Max values\n",
        "   \n",
        "2. DOSE-RESPONSE ANALYSIS:\n",
        "   - Plot L1 → L5 gradient\n",
        "   - Statistical significance tests\n",
        "   \n",
        "3. BASELINE COMPARISON:\n",
        "   - Baselines mean vs L3/L4/L5 mean\n",
        "   - Percentage separation\n",
        "   \n",
        "4. VISUALIZATIONS:\n",
        "   - R_V distribution histograms\n",
        "   - Box plots by group\n",
        "   - Dose-response curve\n",
        "   \n",
        "5. SAVE RESULTS:\n",
        "   - Full CSV with all metrics\n",
        "   - Summary statistics table\n",
        "   - Key findings report\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Expected Results (Based on Phase 1A/1B)\n",
        "\n",
        "### Primary Finding: R_V Dose-Response\n",
        "- **L1 (hint)**: R_V ≈ 1.00 (neutral)\n",
        "- **L2 (simple)**: R_V ≈ 1.01 (neutral)\n",
        "- **L3 (deeper)**: R_V ≈ 0.98 (slight contraction)\n",
        "- **L4 (full)**: R_V ≈ 0.96 (clear contraction)\n",
        "- **L5 (refined)**: R_V ≈ 0.89 (strong contraction)\n",
        "\n",
        "### Control Validations\n",
        "- **Baselines**: R_V ≈ 1.15-1.20 (expansion)\n",
        "- **Long control**: R_V ≈ 1.09 (expansion despite length)\n",
        "- **Pseudo-recursive**: R_V ≈ 1.00 (neutral despite meta-talk)\n",
        "\n",
        "### Success Criteria\n",
        "✅ Clear dose-response gradient (L1→L5)  \n",
        "✅ >15% separation between L4/L5 and baselines  \n",
        "✅ Confounds show no contraction effect  \n",
        "✅ Results stable across N=20 per group\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
